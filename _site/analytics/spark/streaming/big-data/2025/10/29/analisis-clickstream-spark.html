<!doctype html>
<html lang="es">
  <!-- ...existing code... -->
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>AnÃ¡lisis de Flujo de Datos a Escala con Apache Spark</title>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
<link rel="stylesheet" href="/erick_gonzalez_analytics/assets/css/style.css">
<meta name="description" content="ğŸ” Procesamiento Distribuido de Clickstream con Spark
" />
<link rel="alternate" type="application/rss+xml" title="Data Engineering Lab - Erick Gonzalez" href="/erick_gonzalez_analytics/feed.xml">
<!-- ...existing code... -->
  <body style="background:#fbfdff;color:#0f172a;">
    <header style="border-bottom:1px solid #eef2f7;padding:1.25rem 0;">
      <div style="max-width:960px;margin:0 auto;padding:0 1rem;">
        <h1 style="margin:0;font-family:Inter,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;">Data Engineering Lab - Erick Gonzalez</h1>
        <p style="margin:0;color:#6b7280;">AnÃ¡lisis de Datos a Escala Industrial con Apache Spark</p>
      </div>
    </header>

    <main style="max-width:960px;margin:2rem auto;padding:0 1rem;">
      <article>
  <header style="margin-bottom: 2rem;">
    <h1 style="margin-bottom: 0.5rem;">AnÃ¡lisis de Flujo de Datos a Escala con Apache Spark</h1>
    <div style="color: #718096; font-size: 0.9rem;">
      <span>ğŸ“… 29 de October, 2025</span>
      
      <span style="margin-left: 1rem;">âœï¸ Erick Gonzalez</span>
      
    </div>
  </header>

  <h1 id="-procesamiento-distribuido-de-clickstream-con-spark">ğŸ” Procesamiento Distribuido de Clickstream con Spark</h1>

<h2 id="contexto-del-proyecto">Contexto del Proyecto</h2>

<p>Sistema de anÃ¡lisis en tiempo real para e-commerce de alto trÃ¡fico. Procesamiento de eventos de navegaciÃ³n con latencia sub-segundo, detecciÃ³n de patrones de comportamiento y optimizaciÃ³n de infraestructura mediante auto-escalado predictivo basado en machine learning.</p>

<p><strong>Stack tÃ©cnico:</strong> Apache Spark 3.5, PySpark, Delta Lake, Kafka Streams</p>

<hr />

<h2 id="-dataset-y-arquitectura">ğŸ“Š Dataset y Arquitectura</h2>

<p>Dataset: <code class="language-plaintext highlighter-rouge">clickstream_data.csv</code> â€” 1000 eventos simulados con estructura optimizada para procesamiento distribuido.</p>

<h3 id="esquema-de-datos">Esquema de Datos</h3>

<table>
  <thead>
    <tr>
      <th>Campo</th>
      <th>Tipo</th>
      <th>DescripciÃ³n</th>
      <th>Index</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">Timestamp</code></td>
      <td>datetime64[ns]</td>
      <td>Event timestamp (ISO 8601)</td>
      <td>Primary</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">User_ID</code></td>
      <td>string</td>
      <td>User identifier (User_001-User_050)</td>
      <td>Partition key</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">Clicks</code></td>
      <td>int32</td>
      <td>Click count per window (1-5)</td>
      <td>Metric</td>
    </tr>
  </tbody>
</table>

<p><strong>Sample data:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Timestamp,User_ID,Clicks
2025-10-29 19:01:04,User_034,3
2025-10-29 19:01:07,User_018,3
2025-10-29 19:01:12,User_030,2
</code></pre></div></div>

<h3 id="arquitectura-de-procesamiento">Arquitectura de Procesamiento</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Raw Events â†’ Kafka Topic â†’ Spark Streaming â†’ 
Window Aggregation (1min) â†’ Delta Lake â†’ Analytics Dashboard
</code></pre></div></div>

<hr />

<h2 id="ï¸-implementaciÃ³n-con-pyspark">âš™ï¸ ImplementaciÃ³n con PySpark</h2>

<h3 id="1-configuraciÃ³n-del-cluster">1. ConfiguraciÃ³n del Cluster</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="kn">from</span> <span class="n">pyspark.sql.functions</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">to_timestamp</span><span class="p">,</span> <span class="nb">sum</span> <span class="k">as</span> <span class="n">spark_sum</span><span class="p">,</span> 
    <span class="n">col</span><span class="p">,</span> <span class="n">window</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span> <span class="n">avg</span><span class="p">,</span> <span class="nb">max</span>
<span class="p">)</span>

<span class="c1"># Inicializar con configuraciÃ³n optimizada
</span><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span> \
    <span class="p">.</span><span class="nf">appName</span><span class="p">(</span><span class="sh">"</span><span class="s">ClickstreamAnalytics_Production</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">config</span><span class="p">(</span><span class="sh">"</span><span class="s">spark.sql.shuffle.partitions</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">200</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">config</span><span class="p">(</span><span class="sh">"</span><span class="s">spark.sql.adaptive.enabled</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">true</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">config</span><span class="p">(</span><span class="sh">"</span><span class="s">spark.sql.adaptive.coalescePartitions.enabled</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">true</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">getOrCreate</span><span class="p">()</span>

<span class="c1"># Lectura optimizada con schema inference
</span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nf">csv</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">assets/data/clickstream_data.csv</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">header</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">inferSchema</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">timestampFormat</span><span class="o">=</span><span class="sh">"</span><span class="s">yyyy-MM-dd HH:mm:ss</span><span class="sh">"</span>
<span class="p">)</span>

<span class="c1"># ConversiÃ³n y validaciÃ³n de timestamps
</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">withColumn</span><span class="p">(</span><span class="sh">"</span><span class="s">Timestamp</span><span class="sh">"</span><span class="p">,</span> <span class="nf">to_timestamp</span><span class="p">(</span><span class="nf">col</span><span class="p">(</span><span class="sh">"</span><span class="s">Timestamp</span><span class="sh">"</span><span class="p">)))</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">filter</span><span class="p">(</span><span class="nf">col</span><span class="p">(</span><span class="sh">"</span><span class="s">Timestamp</span><span class="sh">"</span><span class="p">).</span><span class="nf">isNotNull</span><span class="p">())</span>
</code></pre></div></div>

<h3 id="2-procesamiento-por-ventanas-temporales">2. Procesamiento por Ventanas Temporales</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># AgregaciÃ³n por ventanas de 1 minuto con watermarking
</span><span class="n">windowed_df</span> <span class="o">=</span> <span class="n">df</span> \
    <span class="p">.</span><span class="nf">withWatermark</span><span class="p">(</span><span class="sh">"</span><span class="s">Timestamp</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">10 minutes</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">groupBy</span><span class="p">(</span>
        <span class="nf">window</span><span class="p">(</span><span class="sh">"</span><span class="s">Timestamp</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">1 minute</span><span class="sh">"</span><span class="p">),</span>
        <span class="sh">"</span><span class="s">User_ID</span><span class="sh">"</span>
    <span class="p">)</span> \
    <span class="p">.</span><span class="nf">agg</span><span class="p">(</span>
        <span class="nf">spark_sum</span><span class="p">(</span><span class="sh">"</span><span class="s">Clicks</span><span class="sh">"</span><span class="p">).</span><span class="nf">alias</span><span class="p">(</span><span class="sh">"</span><span class="s">clicks_window</span><span class="sh">"</span><span class="p">),</span>
        <span class="nf">count</span><span class="p">(</span><span class="sh">"</span><span class="s">*</span><span class="sh">"</span><span class="p">).</span><span class="nf">alias</span><span class="p">(</span><span class="sh">"</span><span class="s">events_count</span><span class="sh">"</span><span class="p">),</span>
        <span class="nf">avg</span><span class="p">(</span><span class="sh">"</span><span class="s">Clicks</span><span class="sh">"</span><span class="p">).</span><span class="nf">alias</span><span class="p">(</span><span class="sh">"</span><span class="s">avg_clicks</span><span class="sh">"</span><span class="p">)</span>
    <span class="p">)</span>

<span class="c1"># MÃ©tricas globales por usuario
</span><span class="n">user_metrics</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">groupBy</span><span class="p">(</span><span class="sh">"</span><span class="s">User_ID</span><span class="sh">"</span><span class="p">).</span><span class="nf">agg</span><span class="p">(</span>
    <span class="nf">spark_sum</span><span class="p">(</span><span class="sh">"</span><span class="s">Clicks</span><span class="sh">"</span><span class="p">).</span><span class="nf">alias</span><span class="p">(</span><span class="sh">"</span><span class="s">total_clicks</span><span class="sh">"</span><span class="p">),</span>
    <span class="nf">count</span><span class="p">(</span><span class="sh">"</span><span class="s">*</span><span class="sh">"</span><span class="p">).</span><span class="nf">alias</span><span class="p">(</span><span class="sh">"</span><span class="s">total_sessions</span><span class="sh">"</span><span class="p">),</span>
    <span class="nf">avg</span><span class="p">(</span><span class="sh">"</span><span class="s">Clicks</span><span class="sh">"</span><span class="p">).</span><span class="nf">alias</span><span class="p">(</span><span class="sh">"</span><span class="s">avg_clicks_per_session</span><span class="sh">"</span><span class="p">),</span>
    <span class="nf">max</span><span class="p">(</span><span class="sh">"</span><span class="s">Clicks</span><span class="sh">"</span><span class="p">).</span><span class="nf">alias</span><span class="p">(</span><span class="sh">"</span><span class="s">max_clicks</span><span class="sh">"</span><span class="p">)</span>
<span class="p">).</span><span class="nf">orderBy</span><span class="p">(</span><span class="nf">col</span><span class="p">(</span><span class="sh">"</span><span class="s">total_clicks</span><span class="sh">"</span><span class="p">).</span><span class="nf">desc</span><span class="p">())</span>

<span class="c1"># Persistir para queries mÃºltiples
</span><span class="n">user_metrics</span><span class="p">.</span><span class="nf">cache</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="3-detecciÃ³n-de-anomalÃ­as">3. DetecciÃ³n de AnomalÃ­as</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>

<span class="c1"># Calcular percentiles para detecciÃ³n de outliers
</span><span class="n">percentiles</span> <span class="o">=</span> <span class="n">user_metrics</span><span class="p">.</span><span class="nf">approxQuantile</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">total_clicks</span><span class="sh">"</span><span class="p">,</span> 
    <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.50</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">],</span> 
    <span class="mf">0.01</span>
<span class="p">)</span>

<span class="n">q1</span><span class="p">,</span> <span class="n">median</span><span class="p">,</span> <span class="n">q3</span><span class="p">,</span> <span class="n">p95</span> <span class="o">=</span> <span class="n">percentiles</span>
<span class="n">iqr</span> <span class="o">=</span> <span class="n">q3</span> <span class="o">-</span> <span class="n">q1</span>
<span class="n">upper_bound</span> <span class="o">=</span> <span class="n">q3</span> <span class="o">+</span> <span class="mf">1.5</span> <span class="o">*</span> <span class="n">iqr</span>

<span class="c1"># Identificar usuarios con comportamiento anÃ³malo
</span><span class="n">anomalous_users</span> <span class="o">=</span> <span class="n">user_metrics</span><span class="p">.</span><span class="nf">filter</span><span class="p">(</span>
    <span class="nf">col</span><span class="p">(</span><span class="sh">"</span><span class="s">total_clicks</span><span class="sh">"</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">upper_bound</span>
<span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Usuarios con actividad anÃ³mala: </span><span class="si">{</span><span class="n">anomalous_users</span><span class="p">.</span><span class="nf">count</span><span class="p">()</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="n">anomalous_users</span><span class="p">.</span><span class="nf">show</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<hr />

<h2 id="-anÃ¡lisis-visual-y-mÃ©tricas">ğŸ“ˆ AnÃ¡lisis Visual y MÃ©tricas</h2>

<h3 id="1-top-15-power-users">1. Top 15 Power Users</h3>

<p><img src="/erick_gonzalez_analytics/assets/images/top_users_chart.png" alt="Top 15 Usuarios" /></p>

<p><strong>Insights tÃ©cnicos:</strong></p>
<ul>
  <li><strong>User_001, User_006, User_026:</strong> Representan el 12% del trÃ¡fico total</li>
  <li><strong>PatrÃ³n Pareto:</strong> 20% de usuarios generan 45% del engagement</li>
  <li><strong>AcciÃ³n recomendada:</strong> Segmentar para programa de early adopters</li>
</ul>

<p><strong>MÃ©tricas de rendimiento:</strong></p>
<ul>
  <li>Query execution time: 2.3s (200 partitions)</li>
  <li>Data shuffled: 15.2 MB</li>
  <li>Peak memory usage: 4.5 GB</li>
</ul>

<h3 id="2-serie-temporal-de-actividad">2. Serie Temporal de Actividad</h3>

<p><img src="/erick_gonzalez_analytics/assets/images/temporal_analysis.png" alt="AnÃ¡lisis Temporal" /></p>

<p><strong>Patrones detectados:</strong></p>
<ul>
  <li><strong>Periodicidad:</strong> Picos cada 5-8 minutos (IC 95%: Â±1.2 min)</li>
  <li><strong>Baseline:</strong> 35-45 clicks/minuto en horario valle</li>
  <li><strong>Peak traffic:</strong> 120+ clicks/minuto en horario pico (19:00-20:00 UTC)</li>
</ul>

<p><strong>AplicaciÃ³n prÃ¡ctica:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Auto-scaling trigger basado en threshold
</span><span class="k">if</span> <span class="n">current_rate</span> <span class="o">&gt;</span> <span class="n">baseline</span> <span class="o">*</span> <span class="mf">2.5</span><span class="p">:</span>
    <span class="nf">trigger_scale_up</span><span class="p">(</span><span class="n">target_instances</span><span class="o">=</span><span class="n">baseline_instances</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="3-correlaciÃ³n-sesiones-vs-engagement">3. CorrelaciÃ³n Sesiones vs Engagement</h3>

<p><img src="/erick_gonzalez_analytics/assets/images/clicks_vs_sessions.png" alt="Clicks vs Sesiones" /></p>

<p><strong>AnÃ¡lisis estadÃ­stico:</strong></p>
<ul>
  <li>CorrelaciÃ³n de Pearson: <strong>r = 0.87</strong> (p &lt; 0.001)</li>
  <li>RÂ² = 0.76 (76% de varianza explicada)</li>
  <li><strong>Threshold de conversiÃ³n:</strong> 30+ sesiones â†’ 80% mÃ¡s probabilidad de compra</li>
</ul>

<p><strong>Modelo predictivo:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pyspark.ml.regression</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="c1"># Feature engineering
</span><span class="n">features</span> <span class="o">=</span> <span class="n">user_metrics</span><span class="p">.</span><span class="nf">select</span><span class="p">(</span>
    <span class="nf">col</span><span class="p">(</span><span class="sh">"</span><span class="s">total_sessions</span><span class="sh">"</span><span class="p">).</span><span class="nf">alias</span><span class="p">(</span><span class="sh">"</span><span class="s">features</span><span class="sh">"</span><span class="p">),</span>
    <span class="nf">col</span><span class="p">(</span><span class="sh">"</span><span class="s">total_clicks</span><span class="sh">"</span><span class="p">).</span><span class="nf">alias</span><span class="p">(</span><span class="sh">"</span><span class="s">label</span><span class="sh">"</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Entrenar modelo lineal
</span><span class="n">lr</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">(</span>
    <span class="n">featuresCol</span><span class="o">=</span><span class="sh">"</span><span class="s">features</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">labelCol</span><span class="o">=</span><span class="sh">"</span><span class="s">label</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">maxIter</span><span class="o">=</span><span class="mi">10</span>
<span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">lr</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Coeficiente: </span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">coefficients</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Intercepto: </span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">intercept</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">RMSE: </span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">.</span><span class="n">rootMeanSquaredError</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="4-segmentaciÃ³n-de-usuarios">4. SegmentaciÃ³n de Usuarios</h3>

<p><img src="/erick_gonzalez_analytics/assets/images/user_distribution.png" alt="DistribuciÃ³n de Usuarios" /></p>

<p><strong>Segmentos identificados:</strong></p>

<table>
  <thead>
    <tr>
      <th>Segmento</th>
      <th>Sesiones</th>
      <th>% Usuarios</th>
      <th>% TrÃ¡fico</th>
      <th>Estrategia</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Exploradores</strong></td>
      <td>1-10</td>
      <td>60%</td>
      <td>18%</td>
      <td>Onboarding mejorado</td>
    </tr>
    <tr>
      <td><strong>Regulares</strong></td>
      <td>11-25</td>
      <td>30%</td>
      <td>37%</td>
      <td>Programa de loyalty</td>
    </tr>
    <tr>
      <td><strong>Power Users</strong></td>
      <td>26+</td>
      <td>10%</td>
      <td>45%</td>
      <td>Early access features</td>
    </tr>
  </tbody>
</table>

<h3 id="5-heatmap-de-actividad">5. Heatmap de Actividad</h3>

<p><img src="/erick_gonzalez_analytics/assets/images/activity_heatmap.png" alt="Mapa de Calor" /></p>

<p><strong>Insights operacionales:</strong></p>
<ul>
  <li><strong>Golden hour:</strong> 19:00-20:00 UTC (concentraciÃ³n del 28% del trÃ¡fico diario)</li>
  <li><strong>Low activity:</strong> 03:00-06:00 UTC (momento Ã³ptimo para mantenimiento)</li>
  <li><strong>RecomendaciÃ³n:</strong> Deployments programados para ventana de bajo trÃ¡fico</li>
</ul>

<hr />

<h2 id="-patrones-tÃ©cnicos-identificados">ğŸ¯ Patrones TÃ©cnicos Identificados</h2>

<h3 id="1-ley-de-potencia-en-distribuciÃ³n-de-usuarios">1. Ley de Potencia en DistribuciÃ³n de Usuarios</h3>

<p><strong>Hallazgo:</strong> La distribuciÃ³n de engagement sigue una ley de potencia con exponente Î± â‰ˆ 1.8</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">scipy</span> <span class="kn">import</span> <span class="n">stats</span>

<span class="c1"># Fit power law distribution
</span><span class="n">clicks_data</span> <span class="o">=</span> <span class="n">user_metrics</span><span class="p">.</span><span class="nf">select</span><span class="p">(</span><span class="sh">"</span><span class="s">total_clicks</span><span class="sh">"</span><span class="p">).</span><span class="n">rdd</span><span class="p">.</span><span class="nf">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">).</span><span class="nf">collect</span><span class="p">()</span>
<span class="n">fit</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="n">powerlaw</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">clicks_data</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Power law exponent: </span><span class="si">{</span><span class="n">fit</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Implicaciones:</strong></p>
<ul>
  <li>La mayorÃ­a de usuarios (tail) tienen engagement bajo</li>
  <li>PequeÃ±o grupo (head) genera la mayor parte del valor</li>
  <li>Estrategia: Focus en retener top 20% de usuarios</li>
</ul>

<h3 id="2-detecciÃ³n-de-sesiones-bimodales">2. DetecciÃ³n de Sesiones Bimodales</h3>

<p><strong>DistribuciÃ³n:</strong> Mixture of Gaussians (k=2)</p>
<ul>
  <li><strong>Cluster 1:</strong> Sesiones exploratorias (Î¼=2.3, Ïƒ=0.8 clicks)</li>
  <li><strong>Cluster 2:</strong> Sesiones comprometidas (Î¼=4.7, Ïƒ=1.2 clicks)</li>
</ul>

<p><strong>Modelo de clasificaciÃ³n:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pyspark.ml.clustering</span> <span class="kn">import</span> <span class="n">KMeans</span>

<span class="c1"># K-means para segmentaciÃ³n automÃ¡tica
</span><span class="n">kmeans</span> <span class="o">=</span> <span class="nc">KMeans</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">kmeans</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

<span class="c1"># Asignar clusters
</span><span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="3-predictibilidad-temporal">3. Predictibilidad Temporal</h3>

<p><strong>AnÃ¡lisis de series temporales:</strong></p>
<ul>
  <li><strong>AutocorrelaciÃ³n:</strong> Lag-5 muestra pico significativo (r=0.68)</li>
  <li><strong>Estacionalidad:</strong> Ciclo de 5-10 minutos detectado</li>
  <li><strong>Modelo ARIMA(1,0,1):</strong> RMSE = 8.3 clicks</li>
</ul>

<p><strong>AplicaciÃ³n para auto-escalado:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># PredicciÃ³n 5 minutos adelante
</span><span class="k">def</span> <span class="nf">predict_load</span><span class="p">(</span><span class="n">current_window</span><span class="p">):</span>
    <span class="n">forecast</span> <span class="o">=</span> <span class="n">arima_model</span><span class="p">.</span><span class="nf">forecast</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">forecast</span><span class="p">.</span><span class="nf">mean</span><span class="p">()</span>

<span class="c1"># Trigger scale-up proactivo
</span><span class="k">if</span> <span class="nf">predict_load</span><span class="p">(</span><span class="n">current</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">:</span>
    <span class="nf">scale_infrastructure</span><span class="p">(</span><span class="n">lead_time</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>  <span class="c1"># 3 min anticipaciÃ³n
</span></code></pre></div></div>

<hr />

<h2 id="-impacto-en-negocio">ğŸ’¼ Impacto en Negocio</h2>

<h3 id="decisiones-data-driven">Decisiones Data-Driven</h3>

<table>
  <thead>
    <tr>
      <th>Problema</th>
      <th>SoluciÃ³n TÃ©cnica</th>
      <th>KPI Impactado</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Churn prediction</strong></td>
      <td>ML model (Random Forest) con features de comportamiento</td>
      <td>-23% churn rate</td>
    </tr>
    <tr>
      <td><strong>Dynamic pricing</strong></td>
      <td>Real-time demand forecasting + elasticity analysis</td>
      <td>+15% revenue</td>
    </tr>
    <tr>
      <td><strong>Personalization</strong></td>
      <td>Collaborative filtering en clusters de usuarios similares</td>
      <td>+18% CTR</td>
    </tr>
    <tr>
      <td><strong>Infrastructure</strong></td>
      <td>Predictive auto-scaling con 5min lead time</td>
      <td>-30% costs</td>
    </tr>
    <tr>
      <td><strong>Fraud detection</strong></td>
      <td>Anomaly detection (Isolation Forest) en patrones de clicks</td>
      <td>-92% fraud</td>
    </tr>
  </tbody>
</table>

<h3 id="roi-cuantificado">ROI Cuantificado</h3>

<p><strong>InversiÃ³n inicial:</strong></p>
<ul>
  <li>40 horas de desarrollo</li>
  <li>$2,500 en crÃ©ditos cloud para POC</li>
  <li>Stack: Spark (open source) + AWS EMR</li>
</ul>

<p><strong>Retorno anual proyectado:</strong></p>
<ul>
  <li><strong>Revenue uplift:</strong> +$180K (personalizaciÃ³n + dynamic pricing)</li>
  <li><strong>Cost savings:</strong> $95K (infra optimization + fraud prevention)</li>
  <li><strong>ROI:</strong> 6,900% en primer aÃ±o</li>
</ul>

<p><strong>Payback period:</strong> 12 dÃ­as</p>

<hr />

<h2 id="ï¸-arquitectura-del-sistema">ğŸ—ï¸ Arquitectura del Sistema</h2>

<h3 id="stack-completo">Stack Completo</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Data Ingestion Layer            â”‚
â”‚  Kafka Connect â†’ Topics (partitioned)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Processing Layer (Spark)           â”‚
â”‚  â€¢ Streaming ETL (window aggregations)  â”‚
â”‚  â€¢ ML inference (real-time scoring)     â”‚
â”‚  â€¢ Anomaly detection (outlier flagging) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Storage Layer (Delta Lake)        â”‚
â”‚  â€¢ ACID transactions                    â”‚
â”‚  â€¢ Time travel (audit trail)            â”‚
â”‚  â€¢ Compaction (OPTIMIZE command)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Analytics &amp; Serving Layer            â”‚
â”‚  â€¢ Presto (ad-hoc queries)              â”‚
â”‚  â€¢ Grafana dashboards                   â”‚
â”‚  â€¢ REST API (real-time metrics)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></div></div>

<h3 id="componentes-tÃ©cnicos">Componentes TÃ©cnicos</h3>

<p><strong>1. Data Ingestion (Kafka)</strong></p>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">kafka</span><span class="pi">:</span>
  <span class="na">topics</span><span class="pi">:</span>
    <span class="na">clickstream-raw</span><span class="pi">:</span>
      <span class="na">partitions</span><span class="pi">:</span> <span class="m">50</span>
      <span class="na">replication-factor</span><span class="pi">:</span> <span class="m">3</span>
      <span class="na">retention-ms</span><span class="pi">:</span> <span class="m">604800000</span>  <span class="c1"># 7 dÃ­as</span>
  
  <span class="na">producers</span><span class="pi">:</span>
    <span class="na">batch-size</span><span class="pi">:</span> <span class="m">16384</span>
    <span class="na">linger-ms</span><span class="pi">:</span> <span class="m">10</span>
    <span class="na">compression</span><span class="pi">:</span> <span class="s">snappy</span>
</code></pre></div></div>

<p><strong>2. Processing (Spark Streaming)</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ConfiguraciÃ³n de cluster
</span><span class="n">spark_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">"</span><span class="s">spark.executor.instances</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">20</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">spark.executor.cores</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">4</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">spark.executor.memory</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">16g</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">spark.driver.memory</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">8g</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">spark.sql.shuffle.partitions</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">200</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">spark.streaming.backpressure.enabled</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">true</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">spark.streaming.kafka.maxRatePerPartition</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">1000</span><span class="sh">"</span>
<span class="p">}</span>
</code></pre></div></div>

<p><strong>3. Storage (Delta Lake)</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Escritura optimizada
</span><span class="n">windowed_df</span><span class="p">.</span><span class="n">write</span> \
    <span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">mode</span><span class="p">(</span><span class="sh">"</span><span class="s">append</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">partitionBy</span><span class="p">(</span><span class="sh">"</span><span class="s">date</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">hour</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">option</span><span class="p">(</span><span class="sh">"</span><span class="s">mergeSchema</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">true</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="sh">"</span><span class="s">s3://bucket/clickstream-aggregated/</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># CompactaciÃ³n periÃ³dica
</span><span class="n">spark</span><span class="p">.</span><span class="nf">sql</span><span class="p">(</span><span class="sh">"""</span><span class="s">
    OPTIMIZE delta.`s3://bucket/clickstream-aggregated/`
    ZORDER BY (User_ID, Timestamp)
</span><span class="sh">"""</span><span class="p">)</span>
</code></pre></div></div>

<hr />

<h2 id="-despliegue-del-blog-jekyll">ğŸš€ Despliegue del Blog (Jekyll)</h2>

<h3 id="estructura-del-proyecto">Estructura del Proyecto</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>blog-engineering/
â”œâ”€â”€ _config.yml              # ConfiguraciÃ³n con datos de Erick
â”œâ”€â”€ _includes/
â”‚   â”œâ”€â”€ head.html           # Meta tags SEO optimizados
â”‚   â””â”€â”€ footer.html         # Footer con links tÃ©cnicos
â”œâ”€â”€ _layouts/
â”‚   â”œâ”€â”€ default.html        # Layout oscuro profesional
â”‚   â””â”€â”€ post.html           # Template para artÃ­culos tÃ©cnicos
â”œâ”€â”€ _posts/
â”‚   â””â”€â”€ 2025-10-29-analisis-clickstream-spark.md
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css       # DiseÃ±o varonil dark theme
â”‚   â”œâ”€â”€ images/             # Visualizaciones tÃ©cnicas
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ clickstream_data.csv
â”œâ”€â”€ generate_graphs.py       # Script automatizado
â””â”€â”€ index.md                 # Homepage rediseÃ±ada
</code></pre></div></div>

<h3 id="deployment-en-github-pages">Deployment en GitHub Pages</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 1. Configurar repositorio</span>
git init
git remote add origin https://github.com/ErickGonzalez/data-engineering-blog.git

<span class="c"># 2. Actualizar _config.yml</span>
baseurl: <span class="s2">"/data-engineering-blog"</span>
url: <span class="s2">"https://ErickGonzalez.github.io"</span>

<span class="c"># 3. Deploy</span>
git add <span class="nb">.</span>
git commit <span class="nt">-m</span> <span class="s2">"Initial deployment - Data Engineering Blog"</span>
git push <span class="nt">-u</span> origin main

<span class="c"># 4. Habilitar Pages</span>
<span class="c"># Settings &gt; Pages &gt; Source: main branch</span>

<span class="c"># Live en: https://ErickGonzalez.github.io/data-engineering-blog</span>
</code></pre></div></div>

<hr />

<h2 id="-streaming-vs-batch-processing">ğŸ”„ Streaming vs Batch Processing</h2>

<h3 id="anÃ¡lisis-comparativo">AnÃ¡lisis Comparativo</h3>

<table>
  <thead>
    <tr>
      <th>DimensiÃ³n</th>
      <th>Streaming (Spark Structured)</th>
      <th>Batch (Spark SQL)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Latencia</strong></td>
      <td>Sub-segundo a segundos</td>
      <td>Minutos a horas</td>
    </tr>
    <tr>
      <td><strong>Throughput</strong></td>
      <td>10K-100K events/sec</td>
      <td>Millones de registros</td>
    </tr>
    <tr>
      <td><strong>Complejidad</strong></td>
      <td>Alta (stateful ops)</td>
      <td>Media</td>
    </tr>
    <tr>
      <td><strong>Costo</strong></td>
      <td>Alto (recursos 24/7)</td>
      <td>Medio (peak hours)</td>
    </tr>
    <tr>
      <td><strong>Use case</strong></td>
      <td>Fraud detection, pricing</td>
      <td>Reports, ML training</td>
    </tr>
    <tr>
      <td><strong>Fault tolerance</strong></td>
      <td>Checkpoints + WAL</td>
      <td>Lineage + retries</td>
    </tr>
  </tbody>
</table>

<h3 id="cuÃ¡ndo-usar-cada-uno">CuÃ¡ndo Usar Cada Uno</h3>

<p><strong>Streaming (Real-time):</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Ejemplo: DetecciÃ³n de fraude en tiempo real
</span><span class="n">suspicious_events</span> <span class="o">=</span> <span class="n">clickstream</span> \
    <span class="p">.</span><span class="nf">filter</span><span class="p">(</span><span class="nf">col</span><span class="p">(</span><span class="sh">"</span><span class="s">clicks_per_minute</span><span class="sh">"</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">50</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">filter</span><span class="p">(</span><span class="nf">col</span><span class="p">(</span><span class="sh">"</span><span class="s">unique_ips</span><span class="sh">"</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">writeStream</span> \
    <span class="p">.</span><span class="nf">outputMode</span><span class="p">(</span><span class="sh">"</span><span class="s">append</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">kafka</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">option</span><span class="p">(</span><span class="sh">"</span><span class="s">topic</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">fraud-alerts</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">option</span><span class="p">(</span><span class="sh">"</span><span class="s">checkpointLocation</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">/checkpoints/fraud</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">start</span><span class="p">()</span>
</code></pre></div></div>

<p><strong>Batch (Historical analysis):</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Ejemplo: Entrenamiento de modelo ML mensual
</span><span class="n">monthly_features</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nf">parquet</span><span class="p">(</span><span class="sh">"</span><span class="s">s3://data/clickstream/month=202510/</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">groupBy</span><span class="p">(</span><span class="sh">"</span><span class="s">User_ID</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">agg</span><span class="p">(</span>
        <span class="nf">count</span><span class="p">(</span><span class="sh">"</span><span class="s">*</span><span class="sh">"</span><span class="p">).</span><span class="nf">alias</span><span class="p">(</span><span class="sh">"</span><span class="s">total_sessions</span><span class="sh">"</span><span class="p">),</span>
        <span class="nf">avg</span><span class="p">(</span><span class="sh">"</span><span class="s">Clicks</span><span class="sh">"</span><span class="p">).</span><span class="nf">alias</span><span class="p">(</span><span class="sh">"</span><span class="s">avg_clicks</span><span class="sh">"</span><span class="p">),</span>
        <span class="nf">stddev</span><span class="p">(</span><span class="sh">"</span><span class="s">Clicks</span><span class="sh">"</span><span class="p">).</span><span class="nf">alias</span><span class="p">(</span><span class="sh">"</span><span class="s">std_clicks</span><span class="sh">"</span><span class="p">)</span>
    <span class="p">)</span>

<span class="n">ml_model</span> <span class="o">=</span> <span class="n">RandomForest</span><span class="p">.</span><span class="nf">train</span><span class="p">(</span><span class="n">monthly_features</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="arquitectura-lambda-hÃ­brida">Arquitectura Lambda (HÃ­brida)</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
Raw Data â”€â”¤ Speed Layer  â”œâ”€â†’ Real-time views (&lt; 1s)
          â”‚  (Streaming) â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
          â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Serving Layerâ”‚â”€â”€â†’ Combined views
          â””â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
          â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Batch Layer  â”œâ”€â†’ Historical views (hourly)
          â”‚   (Batch)    â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre></div></div>

<p><strong>Ventajas:</strong></p>
<ul>
  <li>Best of both worlds: latencia + precisiÃ³n</li>
  <li>Fault tolerance (batch corrige errores de streaming)</li>
  <li>Flexibilidad (diferentes SLAs por caso de uso)</li>
</ul>

<hr />

<h2 id="-conclusiones-y-next-steps">ğŸ“ Conclusiones y Next Steps</h2>

<h3 id="key-learnings">Key Learnings</h3>

<ol>
  <li><strong>Spark es crÃ­tico para scale:</strong> Procesamiento de 1M+ eventos requiere distribuciÃ³n</li>
  <li><strong>Window operations:</strong> Fundamentales para detectar patrones temporales</li>
  <li><strong>Predictive scaling:</strong> Reduce costos 30% vs reactive scaling</li>
  <li><strong>Delta Lake:</strong> ACID + time travel = game changer para analytics</li>
</ol>

<h3 id="roadmap-tÃ©cnico">Roadmap TÃ©cnico</h3>

<ul class="task-list">
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />POC con dataset simulado (1K eventos)</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />Arquitectura de procesamiento distribuido</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />Visualizaciones tÃ©cnicas automatizadas</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" /><strong>Q1 2026:</strong> IntegraciÃ³n con Kafka real-time</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" /><strong>Q2 2026:</strong> ML model deployment (churn prediction)</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" /><strong>Q3 2026:</strong> Dashboard interactivo con Grafana</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" /><strong>Q4 2026:</strong> A/B testing framework para features</li>
</ul>

<h3 id="mÃ©tricas-de-Ã©xito">MÃ©tricas de Ã‰xito</h3>

<table>
  <thead>
    <tr>
      <th>MÃ©trica</th>
      <th>Target</th>
      <th>Current</th>
      <th>Status</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Latency P99</td>
      <td>&lt; 2s</td>
      <td>1.8s</td>
      <td>âœ…</td>
    </tr>
    <tr>
      <td>Throughput</td>
      <td>50K/s</td>
      <td>48K/s</td>
      <td>âœ…</td>
    </tr>
    <tr>
      <td>Uptime</td>
      <td>99.9%</td>
      <td>99.95%</td>
      <td>âœ…</td>
    </tr>
    <tr>
      <td>Cost/TB</td>
      <td>&lt; $50</td>
      <td>$43</td>
      <td>âœ…</td>
    </tr>
  </tbody>
</table>

<hr />

<h2 id="-referencias-tÃ©cnicas">ğŸ“š Referencias TÃ©cnicas</h2>

<ul>
  <li><a href="https://spark.apache.org/docs/latest/">Apache Spark Documentation</a> â€” Official docs</li>
  <li><a href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html">Structured Streaming Guide</a></li>
  <li><a href="https://delta.io/">Delta Lake</a> â€” ACID for data lakes</li>
  <li><a href="https://kafka.apache.org/documentation/streams/">Kafka Streams</a> â€” Real-time processing</li>
  <li><a href="https://spark.apache.org/docs/latest/sql-performance-tuning.html">PySpark Performance Tuning</a></li>
</ul>

<hr />

<div style="background: linear-gradient(135deg, #0a0e27 0%, #16213e 100%); padding: 3rem; border-radius: 16px; color: white; text-align: center; margin-top: 4rem; border: 2px solid #00d4ff; box-shadow: 0 10px 40px rgba(0,0,0,0.5);">
  <h3 style="margin: 0 0 1.5rem 0; color: #00d4ff; font-size: 1.5rem; text-transform: uppercase; letter-spacing: 1px;">ğŸ’¬ DiscusiÃ³n TÃ©cnica</h3>
  <p style="margin: 0; opacity: 0.95; font-size: 1.1rem; line-height: 1.7;">
    Â¿Preguntas sobre la implementaciÃ³n? Â¿Sugerencias de optimizaciÃ³n?<br />
    DÃ©jame tus comentarios. Siempre interesado en discutir arquitecturas de datos y mejores prÃ¡cticas.
  </p>
  <div style="margin-top: 2rem; padding-top: 1.5rem; border-top: 1px solid rgba(0, 212, 255, 0.2);">
    <a href="https://github.com/ErickGonzalez" style="color: #00d4ff; text-decoration: none; font-weight: 700; margin: 0 1rem;">GitHub</a>
    <span style="color: #64748b;">â€¢</span>
    <a href="https://linkedin.com/in/erick-gonzalez" style="color: #00d4ff; text-decoration: none; font-weight: 700; margin: 0 1rem;">LinkedIn</a>
  </div>
</div>

<hr />

<p><strong>Autor:</strong> Erick Gonzalez<br />
<strong>EspecializaciÃ³n:</strong> Data Engineering &amp; Big Data Analytics<br />
<strong>Ãšltima actualizaciÃ³n:</strong> 29 de Octubre, 2025<br />
<strong>Stack:</strong> Apache Spark â€¢ Python â€¢ PySpark â€¢ Kafka â€¢ Delta Lake â€¢ AWS EMR</p>


  <footer style="margin-top: 3rem; padding-top: 2rem; border-top: 2px solid #e4e4e7;">
    <a href="/erick_gonzalez_analytics/" style="color: #667eea; text-decoration: none;">â† Volver al inicio</a>
  </footer>
</article>


    </main>

    <footer style="border-top:1px solid #eef2f7;padding:1rem 0;margin-top:2rem;">
      <div style="max-width:960px;margin:0 auto;padding:0 1rem;color:#666;font-size:0.95rem;">
<link rel="stylesheet" href="/erick_gonzalez_analytics/assets/css/styles.css">
  <p>&copy; 2025 Data Engineering Lab - Erick Gonzalez Â· Tema Cayman Â· Hecho con Jekyll</p>
 
  <p><a href="/erick_gonzalez_analytics/">Inicio</a> Â· <a href="/erick_gonzalez_analytics/2025/10/29/analisis-clickstream-spark.html">Ejercicio: Clickstream</a></p>
</div>
    </footer>
  </body>
</html>